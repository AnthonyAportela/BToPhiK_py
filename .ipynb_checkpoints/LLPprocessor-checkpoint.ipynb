{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d1b251-becd-45d4-b843-d05492409ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import awkward as ak\n",
    "import hist as hs\n",
    "import numpy as np\n",
    "import mplhep as hep\n",
    "\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import vector, candidate\n",
    "from coffea.nanoevents import BaseSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852f58d-1eb2-4019-9960-7d15861e5ccc",
   "metadata": {},
   "source": [
    "# coffea processor\n",
    "Meat of algo is in `process` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a276d1-0261-4065-915f-108acec886c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LLPprocessor(processor.ProcessorABC):\n",
    "    \n",
    "    def delta_cls_X(self, events, X):\n",
    "        clusts = ak.zip(\n",
    "            {\n",
    "                'pt': ak.zeros_like(events.cscRechitClusterPhi),\n",
    "                'phi': events.cscRechitClusterPhi,\n",
    "                'eta': events.cscRechitClusterEta,\n",
    "                'E': ak.zeros_like(events.cscRechitClusterPhi),\n",
    "            },\n",
    "            with_name = 'PtEtaPhiMLorentzVector',\n",
    "            behavior = vector.behavior,                 \n",
    "        )        \n",
    "        \n",
    "        if X == 'gLLP':\n",
    "            p = ak.zip(\n",
    "                {\n",
    "                    'pt': events.gLLP_pt,\n",
    "                    'phi': events.gLLP_phi,\n",
    "                    'eta': events.gLLP_eta,\n",
    "                    'E': events.gLLP_e,\n",
    "                },\n",
    "                with_name = 'PtEtaPhiMLorentzVector',\n",
    "                behavior = vector.behavior,                 \n",
    "            )              \n",
    "        elif X == 'leadmuon':\n",
    "            p = ak.zip(\n",
    "                {\n",
    "                    'pt': events.leadMuonPt,\n",
    "                    'phi': events.leadMuonPhi,\n",
    "                    'eta': events.leadMuonEta,\n",
    "                    'E': events.leadMuonE,\n",
    "                },\n",
    "                with_name = 'PtEtaPhiMLorentzVector',\n",
    "                behavior = vector.behavior,                 \n",
    "            )             \n",
    "        else:\n",
    "            raise Exception(f'X = {X} is not \"gLLP\" or \"leadMuon\".')\n",
    "        \n",
    "        cls_p_pairs = ak.cartesian(\n",
    "            {\n",
    "                \"cls\": clusts, \n",
    "                \"p\": p\n",
    "            },\n",
    "            nested = True\n",
    "        )         \n",
    "\n",
    "        deltaR = (cls_p_pairs.cls).delta_r(cls_p_pairs.p)\n",
    "        deltaEta = abs(cls_p_pairs.cls.eta - cls_p_pairs.p.eta)\n",
    "        #deltaPhi = np.sqrt(deltaR**2 - deltaEta**2)\n",
    "        deltaPhi = np.arctan2(np.sin(cls_p_pairs.cls.phi - cls_p_pairs.p.phi), \n",
    "                              np.cos(cls_p_pairs.cls.phi - cls_p_pairs.p.phi))\n",
    "        \n",
    "        deltaR, deltaEta, deltaPhi = ak.flatten(deltaR, axis=2), ak.flatten(deltaEta, axis=2), ak.flatten(deltaPhi, axis=2)\n",
    "        return deltaR, deltaEta, deltaPhi,\n",
    "        \n",
    "    \n",
    "    def process(self, events):\n",
    "        \n",
    "        signame = 'Phi'\n",
    "        \n",
    "        # >>> output dict init >>>\n",
    "        dataset = events.metadata['dataset']\n",
    "        out = {\n",
    "            dataset: {},\n",
    "            f'{dataset}_cuts': {},\n",
    "            f'{dataset}_vars': {},\n",
    "        }\n",
    "        # <<< output dict init <<<\n",
    "        \n",
    "        out[dataset][f'numEvents_pretrigger'] = len(events)\n",
    "        \n",
    "        # >>> some preprocessing >>>\n",
    "        \n",
    "            # add a new set of branches that only consists of values pertaining to muons\n",
    "        muoncut = abs(events.lepPdgId) == 13\n",
    "        events['muonE'] = events.lepE[muoncut]\n",
    "        events['muonPt'] = events.lepPt[muoncut]\n",
    "        events['muonEta'] = events.lepEta[muoncut]\n",
    "        events['muonPhi'] = events.lepPhi[muoncut]\n",
    "        events['muonPdgId'] = events.lepPdgId[muoncut]\n",
    "        events['muonDZ'] = events.lepDZ[muoncut]\n",
    "        events['muonLooseId'] = events.lepLooseId[muoncut]\n",
    "        events['muonTightId'] = events.lepTightId[muoncut] \n",
    "        events['muonType'] = events.lepMuonType[muoncut]\n",
    "        events['muonQuality'] = events.lepMuonQuality[muoncut]\n",
    "        events['muon_passHLTFilter'] = events.lepMuon_passHLTFilter[muoncut]\n",
    "        events = events[ak.count(events.muonPt, axis=1) > 0] #kill all events with empty muons\n",
    "        out[dataset][f'numEvents_|muonId| == 13'] = len(events.muonPt)\n",
    "        \n",
    "        \n",
    "            # cut and mutate events based on this new branch\n",
    "        def muoncutter(events, muoncut):\n",
    "            events['muonE'] = events.muonE[muoncut]\n",
    "            events['muonPt'] = events.muonPt[muoncut]\n",
    "            events['muonEta'] = events.muonEta[muoncut]\n",
    "            events['muonPhi'] = events.muonPhi[muoncut]\n",
    "            events['muonPdgId'] = events.muonPdgId[muoncut]\n",
    "            events['muonDZ'] = events.muonDZ[muoncut]\n",
    "            events['muonLooseId'] = events.muonLooseId[muoncut]\n",
    "            events['muonTightId'] = events.muonTightId[muoncut]\n",
    "            events['muonType'] = events.muonType[muoncut]\n",
    "            events['muonQuality'] = events.muonQuality[muoncut]\n",
    "            events['muon_passHLTFilter'] = events.muon_passHLTFilter[muoncut]\n",
    "            events = events[ak.count(events.muonPt, axis=1) > 0] #kill all events with empty muons\n",
    "            return events\n",
    "\n",
    "        events = muoncutter(events, ak.any(events.muon_passHLTFilter[:,:,range(60,68)], axis=2))\n",
    "        out[dataset][f'numEvents_muonHLTReq'] = len(events.muonPt)\n",
    "            \n",
    "        events = muoncutter(events, abs(events.muonEta) < 1.5)\n",
    "        out[dataset][f'numEvents_|muonEta| < 1.5'] = len(events.muonPt)\n",
    "        events = muoncutter(events, events.muonPt > 7)\n",
    "        out[dataset][f'numEvents_muonPt > 7'] = len(events.muonPt)\n",
    "        \n",
    "        events = muoncutter(events, events.muonQuality >= 2**25)\n",
    "        out[dataset][f'numEvents_soft_muon_ID'] = len(events.muonPt) \n",
    "            \n",
    "            # finally keep only the leading muon\n",
    "        leadcut = (ak.max(events.muonPt, axis=1, mask_identity=True) == events.muonPt)\n",
    "        events['leadMuonE'] = events.muonE[leadcut][:,0]\n",
    "        events['leadMuonPt'] = events.muonPt[leadcut][:,0]\n",
    "        events['leadMuonEta'] = events.muonEta[leadcut][:,0]\n",
    "        events['leadMuonPhi'] = events.muonPhi[leadcut][:,0]\n",
    "        events['leadMuonPdgId'] = events.muonPdgId[leadcut][:,0]\n",
    "        events['leadMuonDZ'] = events.muonDZ[leadcut][:,0]\n",
    "        events['leadMuonLooseId'] = events.muonLooseId[leadcut][:,0]\n",
    "        events['leadMuonTightId'] = events.muonTightId[leadcut][:,0]\n",
    "        events['leadMuonType'] = events.muonType[leadcut][:,0]\n",
    "        events['leadMuonQuality'] = events.muonQuality[leadcut][:,0]\n",
    "        events['leadMuon_passHLTFilter'] = events.muon_passHLTFilter[leadcut][:,0]                \n",
    "        out[dataset][f'numEvents_leadMuon_cut'] = len(events.leadMuonPt)\n",
    "\n",
    "            # add branches pertaining to deltaR between either leading muon and cluster, or llp and cluster\n",
    "        if signame in dataset:\n",
    "            cls_llp_deltaR, cls_llp_deltaEta, cls_llp_deltaPhi = self.delta_cls_X(events, X='gLLP')\n",
    "            events['cscRechitCluster_llp_deltaR'] = cls_llp_deltaR\n",
    "            events['cscRechitCluster_llp_deltaEta'] = cls_llp_deltaEta\n",
    "            events['cscRechitCluster_llp_deltaPhi'] = cls_llp_deltaPhi\n",
    "\n",
    "            events['gLLP_decay_vertex_z_matched'] = events.gLLP_decay_vertex_z.mask[ak.any(cls_llp_deltaR < .4, axis=1)]\n",
    "            events['gLLP_e_matched'] = events.gLLP_e.mask[ak.any(cls_llp_deltaR < .4, axis=1)]\n",
    "            \n",
    "        cls_leadmuon_deltaR, cls_leadmuon_deltaEta, cls_leadmuon_deltaPhi = self.delta_cls_X(events, X='leadmuon')\n",
    "        events['cscRechitCluster_leadmuon_deltaR'] = cls_leadmuon_deltaR\n",
    "        events['cscRechitCluster_leadmuon_deltaEta'] = cls_leadmuon_deltaEta\n",
    "        events['cscRechitCluster_leadmuon_deltaPhi'] = cls_leadmuon_deltaPhi\n",
    "        # <<< some preprocessing <<<\n",
    "\n",
    "        \n",
    "        # >>> cut definitions >>> \n",
    "        dummy = ak.values_astype(ak.ones_like(events.nCscRechitClusters), 'bool') #dummy truth vector of same shape as csc variables\n",
    "        cscCuts = {\n",
    "            'posttrigger': dummy, \n",
    "            'llp_acc': (events.gLLP_csc == 1) if signame in dataset else dummy,\n",
    "            'num Cluster > 0': (events.nCscRechitClusters > 0),\n",
    "            'dR_gllp_cls < .4': (events.cscRechitCluster_llp_deltaR < .4) if signame in dataset else dummy,\n",
    "            'dR_lmuon_cls > .8': (events.cscRechitCluster_leadmuon_deltaR > .8),\n",
    "            'ME1112_veto': ((events.cscRechitClusterNRechitChamberPlus11 <= 0)&(events.cscRechitClusterNRechitChamberMinus11 <= 0)&\n",
    "                            (events.cscRechitClusterNRechitChamberPlus12 <= 0)&(events.cscRechitClusterNRechitChamberMinus12 <= 0)),\n",
    "            're12_veto': (events.cscRechitCluster_match_RE12_0p4 == 0),\n",
    "            'mb1_veto': (events.cscRechitCluster_match_MB1Seg_0p4 == 0),\n",
    "            'rb1_veto': (events.cscRechitCluster_match_RB1_0p4 == 0),\n",
    "            'muon_veto_pt < 20': (events.cscRechitClusterMuonVetoPt < 20),\n",
    "            '-5 < cls_time < 12.5': ((events.cscRechitClusterTimeWeighted <= 12.5)&(events.cscRechitClusterTimeWeighted >= -5)),\n",
    "            '|cls_timeSpread| < 20': (events.cscRechitClusterTimeSpreadWeightedAll <= 20),\n",
    "            '|cls_eta| < 1.9': (abs(events.cscRechitClusterEta) < 1.9),\n",
    "            'cut_based_ID': (((events.cscRechitClusterNStation10 >  1) & (abs(events.cscRechitClusterEta) < 1.9)) |\n",
    "                             ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 4) & (abs(events.cscRechitClusterEta) < 1.8)) |\n",
    "                             ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 3) & (abs(events.cscRechitClusterEta) < 1.6)) |\n",
    "                             ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 2) & (abs(events.cscRechitClusterEta) < 1.6)) |\n",
    "                             ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 1) & (abs(events.cscRechitClusterEta) < 1.1))),\n",
    "            'cls_size > 130': (events.cscRechitClusterSize >= 130),\n",
    "        }\n",
    "        # <<< cut definitions <<<\n",
    "\n",
    "        # >>> variables to be plotted >>>                \n",
    "        __ = lambda x: x\n",
    "        bins = 30\n",
    "        \n",
    "        #must be same shape as any csc variable\n",
    "        cscVars = {\n",
    "            'cscRechitClusterNRechitChamberPlus11':  [bins,    0,  10, __, ],\n",
    "            'cscRechitClusterNRechitChamberMinus11': [bins,    0,  10, __, ],\n",
    "            'cscRechitClusterNRechitChamberPlus12':  [bins,    0,  10, __, ],\n",
    "            'cscRechitClusterNRechitChamberMinus12': [bins,    0,  10, __, ],\n",
    "            'cscRechitCluster_match_RE12_0p4':       [bins,    0,  10, __, ],\n",
    "            'cscRechitCluster_match_MB1Seg_0p4':     [bins,    0,  10, __, ],\n",
    "            'cscRechitCluster_match_RB1_0p4':        [bins,    0,  10, __, ],\n",
    "            'cscRechitClusterMuonVetoPt':            [bins,    0, 100, __, ],\n",
    "            'cscRechitClusterTimeWeighted':          [bins,  -20,  20, __, ],\n",
    "            'cscRechitClusterTimeSpreadWeightedAll': [bins,    0,  30, __, ],\n",
    "            'cscRechitClusterEta':                   [bins,    0,   3, abs,],\n",
    "            'cscRechitClusterSize':                  [bins,    50, 300, __, ],\n",
    "            'cscRechitClusterNStation10':            [bins,    0,   5, __, ],\n",
    "            'cscRechitClusterAvgStation10':          [bins,    0,   5, abs, ],\n",
    "        }\n",
    "        \n",
    "        if 'background' in dataset: # this is explicitly to protect from unblinding data\n",
    "            cscVars['cscRechitClusterSize'] = [int(bins/5),    50, 100, __, ]\n",
    "\n",
    "        if signame in dataset:\n",
    "            cscVars['cscRechitCluster_llp_deltaR']   = [bins, 0, 5, __,]\n",
    "            cscVars['cscRechitCluster_llp_deltaEta'] = [bins, 0, 5, abs,]\n",
    "            cscVars['cscRechitCluster_llp_deltaPhi'] = [bins, 0, 5, __,]\n",
    "\n",
    "        cscVars['cscRechitCluster_leadmuon_deltaR']   = [bins, 0, 5, __,]\n",
    "        cscVars['cscRechitCluster_leadmuon_deltaEta'] = [bins, 0, 5, abs,]\n",
    "        cscVars['cscRechitCluster_leadmuon_deltaPhi'] = [bins, 0, 5, __,]\n",
    "        \n",
    "        #must be flat variables of length nEvents\n",
    "        eventVars = {\n",
    "            'metEENoise': [bins,   0, 100, __, ],\n",
    "            'gLLP_ctau': [bins, 0, 1e3, __, ],\n",
    "        }\n",
    "        \n",
    "        if signame in dataset:        \n",
    "            eventVars['gLLP_decay_vertex_z'] = [2*bins,   0, 1200, abs, ]\n",
    "            eventVars['gLLP_decay_vertex_z_matched'] = [2*bins,   0, 1200, abs, ]\n",
    "            eventVars['gLLP_e'] = [bins,   0, 100, __, ]\n",
    "            eventVars['gLLP_e_matched'] = [bins,   0, 100, __, ]\n",
    "            \n",
    "        Vars = cscVars | eventVars\n",
    "        # <<< variables to be plotted <<<\n",
    "        \n",
    "        \n",
    "        # >>> create hists >>> \n",
    "        bigCut = cscCuts[list(cscCuts.keys())[0]] #sets first cut\n",
    "        for cut in cscCuts:\n",
    "            out[f'{dataset}_cuts'][cut] = 1       \n",
    "            bigCut = bigCut & cscCuts[cut]\n",
    "            \n",
    "            if bigCut.layout.minmax_depth == (2,2):\n",
    "                temp = ak.any(bigCut, axis=1)\n",
    "            elif bigCut.layout.minmax_depth == (1,1):\n",
    "                temp = bigCut\n",
    "                          \n",
    "            out[dataset][f'numEvents_{cut}'] = sum(temp)\n",
    "            \n",
    "            for var in Vars:\n",
    "\n",
    "                out[f'{dataset}_vars'][var] = 1  \n",
    "                v = Vars[var]\n",
    "                \n",
    "                if bigCut.layout.minmax_depth == (2,2) and events[var].layout.minmax_depth == (1,1):\n",
    "                    temp2 = ak.any(bigCut, axis=1)\n",
    "                else:\n",
    "                    temp2 = bigCut\n",
    "                \n",
    "                data = ak.flatten(events[var][temp2], axis=None)\n",
    "                data = v[3](data)\n",
    "                key = f'{var} with {cut}'\n",
    "                \n",
    "                if signame in dataset:\n",
    "                    out[f'{dataset}_vars'][key] = data.to_list()\n",
    "                    \n",
    "                if 'gLLP_e' in var:\n",
    "                    out[dataset][key] = hs.Hist.new.Reg(v[0], v[1]+1, v[2], name=var, label=var, transform=hs.axis.transform.log).Double()\n",
    "                else:\n",
    "                    out[dataset][key] = hs.Hist.new.Reg(v[0], v[1], v[2], name=var, label=var).Double()\n",
    "                out[dataset][key].fill(data) \n",
    "        # <<< create hists <<<\n",
    "        return out\n",
    "    \n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d4a66-c133-4f89-833b-22b1c2b0ee6c",
   "metadata": {},
   "source": [
    "# Runner\n",
    "Raw data files to be processed into histograms, etc, are called here and processed by the processor defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324c412-9ecd-4969-bd10-88aa97385137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f54f787b5f4cfcb58a26a9043ef9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c81d280>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c6860d0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c81d040>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c88a4f0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c88a6d0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c81d9a0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c88a6d0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c81d430>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c823370>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c81d0a0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c88a130>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c88a310>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c81d4c0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c88a070>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c81dc70>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c6860d0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b387a70a0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b9c823e50>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b93b46490>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b923b3a60>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b93b1c7c0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b93d5e7c0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b3230a3d0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b93b31ca0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b92c5f940>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b920416d0>, taking first instance\n",
      "  warnings.warn(\n",
      "/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py:75: UserWarning: Found duplicate branch nDtRechits in <TTree 'MuonSystem' (218 branches) at 0x7f0b93b1c490>, taking first instance\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "concurrent.futures.process._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 1542, in _work_function\n",
      "    out = processor_instance.process(events)\n",
      "  File \"/tmp/aaportel/ipykernel_29567/4214714218.py\", line 76, in process\n",
      "    muoncut = abs(events.lepPdgId) == 13\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/numpy/lib/mixins.py\", line 54, in func\n",
      "    return ufunc(self)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/awkward/highlevel.py\", line 1411, in __array_ufunc__\n",
      "    return ak._connect._numpy.array_ufunc(ufunc, method, inputs, kwargs)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/awkward/_connect/_numpy.py\", line 250, in array_ufunc\n",
      "    out = ak._util.broadcast_and_apply(\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/awkward/_util.py\", line 1172, in broadcast_and_apply\n",
      "    out = apply(broadcast_pack(inputs, isscalar), 0, user)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/awkward/_util.py\", line 925, in apply\n",
      "    outcontent = apply(nextinputs, depth + 1, user)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/awkward/_util.py\", line 753, in apply\n",
      "    return apply(nextinputs, depth, user)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/awkward/_util.py\", line 750, in apply\n",
      "    nextinputs.append(x.array)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/awkward/operations/convert.py\", line 4713, in _form_to_layout\n",
      "    container[key_format(form_key=fk, attribute=\"offsets\", partition=partnum)]\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/base.py\", line 90, in __getitem__\n",
      "    stack.append(self.extract_column(handle, start, stop))\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/nanoevents/mapping/uproot.py\", line 138, in extract_column\n",
      "    return columnhandle.array(\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\", line 2210, in array\n",
      "    _ranges_or_baskets_to_arrays(\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\", line 3495, in _ranges_or_baskets_to_arrays\n",
      "    uproot.source.futures.delayed_raise(*obj)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/futures.py\", line 36, in delayed_raise\n",
      "    raise exception_value.with_traceback(traceback)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/behaviors/TBranch.py\", line 3416, in chunk_to_basket\n",
      "    basket = uproot.models.TBasket.Model_TBasket.read(\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/model.py\", line 806, in read\n",
      "    self.read_members(chunk, cursor, context, file)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/models/TBasket.py\", line 223, in read_members\n",
      "    ) = cursor.fields(chunk, _tbasket_format1, context)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/cursor.py\", line 197, in fields\n",
      "    return format.unpack(chunk.get(start, stop, self, context))\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/chunk.py\", line 419, in get\n",
      "    self.wait(insist=stop)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/chunk.py\", line 356, in wait\n",
      "    self._raw_data = numpy.frombuffer(self._future.result(), dtype=self._dtype)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/futures.py\", line 116, in result\n",
      "    delayed_raise(*self._excinfo)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/futures.py\", line 36, in delayed_raise\n",
      "    raise exception_value.with_traceback(traceback)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/futures.py\", line 278, in _run\n",
      "    self._result = self._task(resource)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/xrootd.py\", line 218, in task\n",
      "    return partfutures[0].result()\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/futures.py\", line 116, in result\n",
      "    delayed_raise(*self._excinfo)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/futures.py\", line 36, in delayed_raise\n",
      "    raise exception_value.with_traceback(traceback)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/xrootd.py\", line 236, in callback\n",
      "    self._xrd_error(status)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/uproot/source/xrootd.py\", line 118, in _xrd_error\n",
      "    raise OSError(\n",
      "OSError: XRootD error: [ERROR] Operation expired\n",
      "in file root://cmsxrootd.fnal.gov//store/user/christiw/displacedJetMuonAnalyzer/bparking/V1p19/MC_Fall18/v1/v9/normalized/BToKPhi_MuonLLPDecayGenFilter_PhiToPiPlusPiMinus_mPhi1p0_ctau300_1pb_weighted.root\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/concurrent/futures/process.py\", line 246, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 220, in __call__\n",
      "    out = self.function(*args, **kwargs)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 1292, in automatic_retries\n",
      "    raise e\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 1277, in automatic_retries\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 1544, in _work_function\n",
      "    raise Exception(f\"Failed processing file: {item!r}\") from e\n",
      "Exception: Failed processing file: WorkItem(dataset='PhiToPiPlusPiMinus_mPhi1p0_ctau300', filename='root://cmsxrootd.fnal.gov//store/user/christiw/displacedJetMuonAnalyzer/bparking/V1p19/MC_Fall18/v1/v9/normalized/BToKPhi_MuonLLPDecayGenFilter_PhiToPiPlusPiMinus_mPhi1p0_ctau300_1pb_weighted.root', treename='MuonSystem', entrystart=307041, entrystop=409388, fileuuid=b'6\\xd0\\xafdYQ\\x11\\xed\\x92\\xbeP\\n\\x03\\n\\xbe\\xef', usermeta={})\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 781, in _processwith\n",
      "    merged = _watcher(FH, self, reducer, pool)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 401, in _watcher\n",
      "    batch = FH.fetch(len(FH.completed))\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 285, in fetch\n",
      "    raise bad_futures[0].exception()\n",
      "Exception: Failed processing file: WorkItem(dataset='PhiToPiPlusPiMinus_mPhi1p0_ctau300', filename='root://cmsxrootd.fnal.gov//store/user/christiw/displacedJetMuonAnalyzer/bparking/V1p19/MC_Fall18/v1/v9/normalized/BToKPhi_MuonLLPDecayGenFilter_PhiToPiPlusPiMinus_mPhi1p0_ctau300_1pb_weighted.root', treename='MuonSystem', entrystart=307041, entrystop=409388, fileuuid=b'6\\xd0\\xafdYQ\\x11\\xed\\x92\\xbeP\\n\\x03\\n\\xbe\\xef', usermeta={})\n"
     ]
    }
   ],
   "source": [
    "prefix = 'root://cmsxrootd.fnal.gov//store/user/christiw/displacedJetMuonAnalyzer/bparking/V1p19/MC_Fall18/v1/v9/normalized/'\n",
    "fileset = {\n",
    "            # 'PhiToPi0Pi0_mPhi0p3_ctau300':\n",
    "            #     [prefix + 'BToKPhi_MuonLLPDecayGenFilter_PhiToPi0Pi0_mPhi0p3_ctau300_1pb_weighted.root'],\n",
    "            # 'PhiToPi0Pi0_mPhi1p0_ctau300':\n",
    "            #     [prefix + 'BToKPhi_MuonLLPDecayGenFilter_PhiToPi0Pi0_mPhi1p0_ctau300_1pb_weighted.root'],\n",
    "            'PhiToPiPlusPiMinus_mPhi0p3_ctau300':\n",
    "                [prefix + 'BToKPhi_MuonLLPDecayGenFilter_PhiToPiPlusPiMinus_mPhi0p3_ctau300_1pb_weighted.root'],\n",
    "            'PhiToPiPlusPiMinus_mPhi1p0_ctau300':\n",
    "                [prefix + 'BToKPhi_MuonLLPDecayGenFilter_PhiToPiPlusPiMinus_mPhi1p0_ctau300_1pb_weighted.root'],\n",
    "            }\n",
    "#fileset['backgroundNew'] = ['root://cmsxrootd.fnal.gov//store/user/christiw/displacedJetMuonAnalyzer/bparking/V1p19/Data2018_UL/v9/normalized/ParkingBPH4_2018A_goodLumi.root']\n",
    "\n",
    "out = processor.run_uproot_job(\n",
    "    fileset,\n",
    "    treename=\"MuonSystem\",\n",
    "    processor_instance=LLPprocessor(),\n",
    "    executor=processor.futures_executor,\n",
    "    executor_args={\"schema\": BaseSchema, \"workers\": 16},\n",
    "    #executor_args={\"schema\": BaseSchema, \"workers\": 1},\n",
    "    #maxchunks = 1,\n",
    "    # chunksize=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a362a-39f9-4629-8c28-e8f7e30b618a",
   "metadata": {},
   "source": [
    "# Saver\n",
    "A dictionary of histogram objects as well as some other useful info is saved into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e15cdad8-70be-4e22-a05e-3980e41046c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in fileset:\n",
    "    filename = dataset + '.pickle'\n",
    "    outfile = open(filename, 'wb')\n",
    "    pickle.dump(out[dataset], outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676da80c-4269-4d80-9a2d-acfd131ec9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe7ec5-c9a7-43b7-92bc-a22b62f6d37e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
