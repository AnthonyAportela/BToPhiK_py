{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d1b251-becd-45d4-b843-d05492409ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import awkward as ak\n",
    "import hist as hs\n",
    "import numpy as np\n",
    "\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import vector, candidate\n",
    "\n",
    "from coffea.nanoevents import BaseSchema\n",
    "import mplhep as hep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852f58d-1eb2-4019-9960-7d15861e5ccc",
   "metadata": {},
   "source": [
    "# coffea processor\n",
    "Meat of algo is in `process` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a276d1-0261-4065-915f-108acec886c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSCprocessor(processor.ProcessorABC):\n",
    "    \n",
    "    def delta_cls_gLLP(self, events):\n",
    "        clusts = ak.zip(\n",
    "            {\n",
    "                'pt': ak.zeros_like(events.cscRechitClusterPhi),\n",
    "                'phi': events.cscRechitClusterPhi,\n",
    "                'eta': events.cscRechitClusterEta,\n",
    "                'E': ak.zeros_like(events.cscRechitClusterPhi),\n",
    "            },\n",
    "            with_name = 'PtEtaPhiMLorentzVector',\n",
    "            behavior = vector.behavior,                 \n",
    "          )\n",
    "        gLLPs = ak.zip(\n",
    "            {\n",
    "                'pt': events.gLLP_pt,\n",
    "                'phi': events.gLLP_phi,\n",
    "                'eta': events.gLLP_eta,\n",
    "                'E': events.gLLP_e,\n",
    "            },\n",
    "            with_name = 'PtEtaPhiMLorentzVector',\n",
    "            behavior = vector.behavior,                 \n",
    "          )        \n",
    "        cls_llp_pairs = ak.cartesian({\n",
    "            \"cls\": clusts, \n",
    "            \"llp\": gLLPs\n",
    "        }, nested = True) \n",
    "        \n",
    "        deltaR = (cls_llp_pairs.cls).delta_r(cls_llp_pairs.llp)\n",
    "        deltaEta = abs(cls_llp_pairs.cls.eta - cls_llp_pairs.llp.eta)\n",
    "        deltaPhi = np.arctan2(np.sin(cls_llp_pairs.cls.phi - cls_llp_pairs.llp.phi), \n",
    "                              np.cos(cls_llp_pairs.cls.phi - cls_llp_pairs.llp.phi))\n",
    "        \n",
    "        deltaR, deltaEta, deltaPhi = ak.flatten(deltaR, axis=2), ak.flatten(deltaEta, axis=2), ak.flatten(deltaPhi, axis=2)\n",
    "        return deltaR, deltaEta, deltaPhi,\n",
    "    \n",
    "    def delta_cls_leadmuon(self, events):\n",
    "        clusts = ak.zip(\n",
    "            {\n",
    "                'pt': ak.zeros_like(events.cscRechitClusterPhi),\n",
    "                'phi': events.cscRechitClusterPhi,\n",
    "                'eta': events.cscRechitClusterEta,\n",
    "                'E': ak.zeros_like(events.cscRechitClusterPhi),\n",
    "            },\n",
    "            with_name = 'PtEtaPhiMLorentzVector',\n",
    "            behavior = vector.behavior,                 \n",
    "          )\n",
    "        leadMuons = ak.zip(\n",
    "            {\n",
    "                'pt': events.leadMuonPt,\n",
    "                'phi': events.leadMuonPhi,\n",
    "                'eta': events.leadMuonEta,\n",
    "                'E': events.leadMuonE,\n",
    "            },\n",
    "            with_name = 'PtEtaPhiMLorentzVector',\n",
    "            behavior = vector.behavior,                 \n",
    "          ) \n",
    "        cls_muon_pairs = ak.cartesian({\n",
    "            \"cls\": clusts, \n",
    "            \"muon\": leadMuons\n",
    "        }, nested = True)\n",
    " \n",
    "        deltaR = (cls_muon_pairs.cls).delta_r(cls_muon_pairs.muon)\n",
    "        deltaEta = abs(cls_muon_pairs.cls.eta - cls_muon_pairs.muon.eta)\n",
    "        deltaPhi = np.arctan2(np.sin(cls_muon_pairs.cls.phi - cls_muon_pairs.muon.phi), \n",
    "                              np.cos(cls_muon_pairs.cls.phi - cls_muon_pairs.muon.phi))\n",
    "        \n",
    "        deltaR, deltaEta, deltaPhi = ak.flatten(deltaR, axis=2), ak.flatten(deltaEta, axis=2), ak.flatten(deltaPhi, axis=2)\n",
    "        return deltaR, deltaEta, deltaPhi\n",
    "        \n",
    "    \n",
    "    def process(self, events):\n",
    "        \n",
    "        signame = 'Phi'\n",
    "        \n",
    "        # >>> output dict init >>>\n",
    "        dataset = events.metadata['dataset']\n",
    "        out = {\n",
    "            dataset: {},\n",
    "            f'{dataset}_cuts': {},\n",
    "            f'{dataset}_vars': {},\n",
    "        }\n",
    "        # <<< output dict init <<<\n",
    "        \n",
    "        out[dataset][f'numEvents_pretrigger'] = len(events)\n",
    "        \n",
    "        # >>> some preprocessing >>>\n",
    "        \n",
    "            # add a new set of branches that only consists of values pertaining to muons\n",
    "        muoncut = abs(events.lepPdgId) == 13\n",
    "        events['muonE'] = events.lepE[muoncut]\n",
    "        events['muonPt'] = events.lepPt[muoncut]\n",
    "        events['muonEta'] = events.lepEta[muoncut]\n",
    "        events['muonPhi'] = events.lepPhi[muoncut]\n",
    "        events['muonPdgId'] = events.lepPdgId[muoncut]\n",
    "        events['muonDZ'] = events.lepDZ[muoncut]\n",
    "        events['muonLooseId'] = events.lepLooseId[muoncut]\n",
    "        events['muonTightId'] = events.lepTightId[muoncut] \n",
    "        if 'mPhi0p3' in dataset:\n",
    "            events['muonType'] = events.lepMuonType[muoncut]\n",
    "            events['muonQuality'] = events.lepMuonQuality[muoncut]\n",
    "            events['muon_passHLTFilter'] = events.lepMuon_passHLTFilter[muoncut]\n",
    "        events = events[ak.count(events.muonPt, axis=1) > 0] #kill all events with empty muons\n",
    "        out[dataset][f'numEvents_|muonId| == 13'] = len(events.muonPt)\n",
    "        \n",
    "        \n",
    "            # cut and mutate events based on this new branch\n",
    "        def muoncutter(events, muoncut):\n",
    "            events['muonE'] = events.muonE[muoncut]\n",
    "            events['muonPt'] = events.muonPt[muoncut]\n",
    "            events['muonEta'] = events.muonEta[muoncut]\n",
    "            events['muonPhi'] = events.muonPhi[muoncut]\n",
    "            events['muonPdgId'] = events.muonPdgId[muoncut]\n",
    "            events['muonDZ'] = events.muonDZ[muoncut]\n",
    "            events['muonLooseId'] = events.muonLooseId[muoncut]\n",
    "            events['muonTightId'] = events.muonTightId[muoncut]\n",
    "            if 'mPhi0p3' in dataset:\n",
    "                events['muonType'] = events.muonType[muoncut]\n",
    "                events['muonQuality'] = events.muonQuality[muoncut]\n",
    "                events['muon_passHLTFilter'] = events.muon_passHLTFilter[muoncut]\n",
    "            events = events[ak.count(events.muonPt, axis=1) > 0] #kill all events with empty muons\n",
    "            return events\n",
    "\n",
    "        if 'mPhi0p3' in dataset:\n",
    "            events = muoncutter(events, ak.any(events.muon_passHLTFilter[:,:,range(60,68)], axis=2))\n",
    "            out[dataset][f'numEvents_muonHLTReq'] = len(events.muonPt)\n",
    "            \n",
    "        events = muoncutter(events, abs(events.muonEta) < 1.5)\n",
    "        out[dataset][f'numEvents_|muonEta| < 1.5'] = len(events.muonPt)\n",
    "        events = muoncutter(events, events.muonPt > 7)\n",
    "        out[dataset][f'numEvents_muonPt > 7'] = len(events.muonPt)\n",
    "        \n",
    "        if 'mPhi0p3' in dataset:       \n",
    "            events = muoncutter(events, events.muonQuality >= 2**25)\n",
    "            out[dataset][f'numEvents_soft_muon_ID'] = len(events.muonPt) \n",
    "            \n",
    "            # finally keep only the leading muon\n",
    "        leadcut = (ak.max(events.muonPt, axis=1, mask_identity=True) == events.muonPt)\n",
    "        events['leadMuonE'] = events.muonE[leadcut][:,0]\n",
    "        events['leadMuonPt'] = events.muonPt[leadcut][:,0]\n",
    "        events['leadMuonEta'] = events.muonEta[leadcut][:,0]\n",
    "        events['leadMuonPhi'] = events.muonPhi[leadcut][:,0]\n",
    "        events['leadMuonPdgId'] = events.muonPdgId[leadcut][:,0]\n",
    "        events['leadMuonDZ'] = events.muonDZ[leadcut][:,0]\n",
    "        events['leadMuonLooseId'] = events.muonLooseId[leadcut][:,0]\n",
    "        events['leadMuonTightId'] = events.muonTightId[leadcut][:,0]\n",
    "        if 'mPhi0p3' in dataset:\n",
    "            events['leadMuonType'] = events.muonType[leadcut][:,0]\n",
    "            events['leadMuonQuality'] = events.muonQuality[leadcut][:,0]\n",
    "            events['leadMuon_passHLTFilter'] = events.muon_passHLTFilter[leadcut][:,0]                \n",
    "        out[dataset][f'numEvents_leadMuon_cut'] = len(events.leadMuonPt)\n",
    "\n",
    "            # add branches pertaining to deltaR between either leading muon and cluster, or llp and cluster\n",
    "        if signame in dataset:\n",
    "            cls_llp_deltaR, cls_llp_deltaEta, cls_llp_deltaPhi = self.delta_cls_gLLP(events)\n",
    "            events['cscRechitCluster_llp_deltaR'] = cls_llp_deltaR\n",
    "            events['cscRechitCluster_llp_deltaEta'] = cls_llp_deltaEta\n",
    "            events['cscRechitCluster_llp_deltaPhi'] = cls_llp_deltaPhi\n",
    "\n",
    "            events['gLLP_decay_vertex_z_matched'] = events.gLLP_decay_vertex_z.mask[ak.any(cls_llp_deltaR < .4, axis=1)]\n",
    "            events['gLLP_e_matched'] = events.gLLP_e.mask[ak.any(cls_llp_deltaR < .4, axis=1)]\n",
    "            \n",
    "        cls_leadmuon_deltaR, cls_leadmuon_deltaEta, cls_leadmuon_deltaPhi = self.delta_cls_leadmuon(events)\n",
    "        events['cscRechitCluster_leadmuon_deltaR'] = cls_leadmuon_deltaR\n",
    "        events['cscRechitCluster_leadmuon_deltaEta'] = cls_leadmuon_deltaEta\n",
    "        events['cscRechitCluster_leadmuon_deltaPhi'] = cls_leadmuon_deltaPhi\n",
    "        # <<< some preprocessing <<<\n",
    "\n",
    "        \n",
    "        # >>> cut definitions >>> \n",
    "        dummy = ak.values_astype(ak.ones_like(events.nCscRechitClusters), 'bool') #dummy truth vector of same shape as csc variables\n",
    "        cscCuts = {\n",
    "            'posttrigger': dummy, \n",
    "            'llp_acc': (events.gLLP_csc == 1) if signame in dataset else dummy,\n",
    "            'num Cluster > 0': (events.nCscRechitClusters > 0),\n",
    "            'dR_gllp_cls < .4': (events.cscRechitCluster_llp_deltaR < .4) if signame in dataset else dummy,\n",
    "            'dR_lmuon_cls > .8': (events.cscRechitCluster_leadmuon_deltaR > .8),\n",
    "            'ME1112_veto': ((events.cscRechitClusterNRechitChamberPlus11 <= 0)&(events.cscRechitClusterNRechitChamberMinus11 <= 0)&\n",
    "                            (events.cscRechitClusterNRechitChamberPlus12 <= 0)&(events.cscRechitClusterNRechitChamberMinus12 <= 0)),\n",
    "            're12_veto': (events.cscRechitCluster_match_RE12_0p4 == 0),\n",
    "            'mb1_veto': (events.cscRechitCluster_match_MB1Seg_0p4 == 0),\n",
    "            'rb1_veto': (events.cscRechitCluster_match_RB1_0p4 == 0),\n",
    "            'muon_veto_pt < 20': (events.cscRechitClusterMuonVetoPt < 20),\n",
    "            '-5 < cls_time < 12.5': ((events.cscRechitClusterTimeWeighted <= 12.5)&(events.cscRechitClusterTimeWeighted >= -5)),\n",
    "            '|cls_timeSpread| < 20': (events.cscRechitClusterTimeSpreadWeightedAll <= 20),\n",
    "            '|cls_eta| < 1.9': (abs(events.cscRechitClusterEta) < 1.9),\n",
    "            'cut_based_ID': (((events.cscRechitClusterNStation10 >  1) & (abs(events.cscRechitClusterEta) < 1.9)) |\n",
    "                             ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 4) & (abs(events.cscRechitClusterEta) < 1.8)) |\n",
    "                             ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 3) & (abs(events.cscRechitClusterEta) < 1.6)) |\n",
    "                             ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 2) & (abs(events.cscRechitClusterEta) < 1.6)) |\n",
    "                             ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 1) & (abs(events.cscRechitClusterEta) < 1.1))),\n",
    "            'cls_size > 130': (events.cscRechitClusterSize >= 130),\n",
    "        }\n",
    "        # <<< cut definitions <<<\n",
    "\n",
    "        # >>> variables to be plotted >>>                \n",
    "        __ = lambda x: x\n",
    "        bins = 30\n",
    "        \n",
    "        #must be same shape as any csc variable\n",
    "        cscVars = {\n",
    "            'cscRechitClusterNRechitChamberPlus11':  [bins,    0,  10, __, ],\n",
    "            'cscRechitClusterNRechitChamberMinus11': [bins,    0,  10, __, ],\n",
    "            'cscRechitClusterNRechitChamberPlus12':  [bins,    0,  10, __, ],\n",
    "            'cscRechitClusterNRechitChamberMinus12': [bins,    0,  10, __, ],\n",
    "            'cscRechitCluster_match_RE12_0p4':       [bins,    0,  10, __, ],\n",
    "            'cscRechitCluster_match_MB1Seg_0p4':     [bins,    0,  10, __, ],\n",
    "            'cscRechitCluster_match_RB1_0p4':        [bins,    0,  10, __, ],\n",
    "            'cscRechitClusterMuonVetoPt':            [bins,    0, 100, __, ],\n",
    "            'cscRechitClusterTimeWeighted':          [bins,  -20,  20, __, ],\n",
    "            'cscRechitClusterTimeSpreadWeightedAll': [bins,    0,  30, __, ],\n",
    "            'cscRechitClusterEta':                   [bins,    0,   3, abs,],\n",
    "            'cscRechitClusterSize':                  [bins,    50, 300, __, ],\n",
    "            'cscRechitClusterNStation10':            [bins,    0,   5, __, ],\n",
    "            'cscRechitClusterAvgStation10':          [bins,    0,   5, abs, ],\n",
    "        }\n",
    "        \n",
    "        if 'background' in dataset: # this is explicitly to protect from unblinding data\n",
    "            cscVars['cscRechitClusterSize'] = [int(bins/5),    50, 100, __, ]\n",
    "\n",
    "        if signame in dataset:\n",
    "            cscVars['cscRechitCluster_llp_deltaR']   = [bins, 0, 5, __,]\n",
    "            cscVars['cscRechitCluster_llp_deltaEta'] = [bins, 0, 5, abs,]\n",
    "            cscVars['cscRechitCluster_llp_deltaPhi'] = [bins, 0, 5, __,]\n",
    "\n",
    "        cscVars['cscRechitCluster_leadmuon_deltaR']   = [bins, 0, 5, __,]\n",
    "        cscVars['cscRechitCluster_leadmuon_deltaEta'] = [bins, 0, 5, abs,]\n",
    "        cscVars['cscRechitCluster_leadmuon_deltaPhi'] = [bins, 0, 5, __,]\n",
    "        \n",
    "        #must be flat variables of length nEvents\n",
    "        eventVars = {\n",
    "            'metEENoise': [bins,   0, 100, __, ],\n",
    "            'gLLP_ctau': [bins, 0, 1e3, __, ],\n",
    "        }\n",
    "        \n",
    "        if signame in dataset:        \n",
    "            eventVars['gLLP_decay_vertex_z'] = [2*bins,   0, 1200, abs, ]\n",
    "            eventVars['gLLP_decay_vertex_z_matched'] = [2*bins,   0, 1200, abs, ]\n",
    "            eventVars['gLLP_e'] = [bins,   0, 100, __, ]\n",
    "            eventVars['gLLP_e_matched'] = [bins,   0, 100, __, ]\n",
    "            \n",
    "        Vars = cscVars | eventVars\n",
    "        # <<< variables to be plotted <<<\n",
    "        \n",
    "        \n",
    "        # >>> create hists >>> \n",
    "        bigCut = cscCuts[list(cscCuts.keys())[0]] #sets first cut\n",
    "        for cut in cscCuts:\n",
    "            out[f'{dataset}_cuts'][cut] = 1       \n",
    "            bigCut = bigCut & cscCuts[cut]\n",
    "            \n",
    "            if bigCut.layout.minmax_depth == (2,2):\n",
    "                temp = ak.any(bigCut, axis=1)\n",
    "            elif bigCut.layout.minmax_depth == (1,1):\n",
    "                temp = bigCut\n",
    "                          \n",
    "            out[dataset][f'numEvents_{cut}'] = sum(temp)\n",
    "            \n",
    "            for var in Vars:\n",
    "\n",
    "                out[f'{dataset}_vars'][var] = 1  \n",
    "                v = Vars[var]\n",
    "                \n",
    "                if bigCut.layout.minmax_depth == (2,2) and events[var].layout.minmax_depth == (1,1):\n",
    "                    temp2 = ak.any(bigCut, axis=1)\n",
    "                else:\n",
    "                    temp2 = bigCut\n",
    "                \n",
    "                data = ak.flatten(events[var][temp2], axis=None)\n",
    "                data = v[3](data)\n",
    "                key = f'{var} with {cut}'\n",
    "                out[f'{dataset}_vars'][key] = data.to_list()\n",
    "                if 'gLLP_e' in var:\n",
    "                    out[dataset][key] = hs.Hist.new.Reg(v[0], v[1]+1, v[2], name=var, label=var, transform=hs.axis.transform.log).Double()\n",
    "                else:\n",
    "                    out[dataset][key] = hs.Hist.new.Reg(v[0], v[1], v[2], name=var, label=var).Double()\n",
    "                out[dataset][key].fill(data) \n",
    "        # <<< create hists <<<\n",
    "        return out\n",
    "    \n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d4a66-c133-4f89-833b-22b1c2b0ee6c",
   "metadata": {},
   "source": [
    "# Runner\n",
    "Raw data files to be processed into histograms, etc, are called here and processed by the processor defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8324c412-9ecd-4969-bd10-88aa97385137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2495ee67b8844f882f01a1047367c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 781, in _processwith\n",
      "    merged = _watcher(FH, self, reducer, pool)\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 401, in _watcher\n",
      "    batch = FH.fetch(len(FH.completed))\n",
      "  File \"/afs/cern.ch/user/a/aaportel/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py\", line 285, in fetch\n",
      "    raise bad_futures[0].exception()\n",
      "concurrent.futures.process.BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#fileset['PhiToPi0Pi0_mPhi1p0_ctau1000'] = ['root://cmsxrootd.fnal.gov//store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/MC_Fall18/v2/v3/normalized/BToKPhi_MuonGenFilter_mPhi1p0_ctau1000_1pb_weighted.root',]\u001b[39;00m\n\u001b[1;32m     35\u001b[0m fileset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackgroundNew\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot://cmsxrootd.fnal.gov//store/user/christiw/displacedJetMuonAnalyzer/bparking/V1p19/Data2018_UL/v6/normalized/ParkingBPH4_2018A_goodLumi.root\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 38\u001b[0m out \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mrun_uproot_job(\n\u001b[1;32m     39\u001b[0m     fileset,\n\u001b[1;32m     40\u001b[0m     treename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMuonSystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     processor_instance\u001b[38;5;241m=\u001b[39mCSCprocessor(),\n\u001b[1;32m     42\u001b[0m     executor\u001b[38;5;241m=\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mfutures_executor,\n\u001b[1;32m     43\u001b[0m     executor_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m: BaseSchema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m},\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# executor_args={\"schema\": BaseSchema, \"workers\": 1},\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m#maxchunks = 1,\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m#chunksize=100000,\u001b[39;00m\n\u001b[1;32m     47\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/__init__.py:104\u001b[0m, in \u001b[0;36m_run_x_job\u001b[0;34m(fileset, treename, processor_instance, executor, executor_args, pre_executor, pre_args, chunksize, maxchunks, metadata_cache, dynamic_chunksize, format)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# make Runner instance, assume other args are for _work_function & co.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m run \u001b[38;5;241m=\u001b[39m Runner(\n\u001b[1;32m     95\u001b[0m     executor\u001b[38;5;241m=\u001b[39mexecutor,\n\u001b[1;32m     96\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexecutor_args,\n\u001b[1;32m    102\u001b[0m )\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor_instance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py:1588\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, fileset, treename, processor_instance)\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1568\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1569\u001b[0m     fileset: Dict,\n\u001b[1;32m   1570\u001b[0m     treename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1571\u001b[0m     processor_instance: ProcessorABC,\n\u001b[1;32m   1572\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Accumulatable:\n\u001b[1;32m   1573\u001b[0m     \u001b[38;5;124;03m\"\"\"Run the processor_instance on a given fileset\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m \n\u001b[1;32m   1575\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;124;03m            An instance of a class deriving from ProcessorABC\u001b[39;00m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1588\u001b[0m     wrapped_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dataframes:\n\u001b[1;32m   1590\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_out  \u001b[38;5;66;03m# not wrapped anymore\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py:1738\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, fileset, processor_instance, treename)\u001b[0m\n\u001b[1;32m   1732\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_retries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipbadfiles, closure\n\u001b[1;32m   1734\u001b[0m )\n\u001b[1;32m   1736\u001b[0m executor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexe_args)\n\u001b[0;32m-> 1738\u001b[0m wrapped_out, e \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrapped_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1740\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1741\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo chunks returned results, verify ``processor`` instance structure.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1742\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py:813\u001b[0m, in \u001b[0;36mFuturesExecutor.__call__\u001b[0;34m(self, items, function, accumulator)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m     mergepoolinstance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_processwith\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoolinstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmergepool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmergepoolinstance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py:797\u001b[0m, in \u001b[0;36mFuturesExecutor.__call__.<locals>._processwith\u001b[0;34m(pool, mergepool)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accumulate([_decompress(merged), accumulator]), e\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py:781\u001b[0m, in \u001b[0;36mFuturesExecutor.__call__.<locals>._processwith\u001b[0;34m(pool, mergepool)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mergepool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 781\u001b[0m         merged \u001b[38;5;241m=\u001b[39m \u001b[43m_watcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreducer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m         merged \u001b[38;5;241m=\u001b[39m _watcher(FH, \u001b[38;5;28mself\u001b[39m, reducer, mergepool)\n",
      "File \u001b[0;32m~/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py:401\u001b[0m, in \u001b[0;36m_watcher\u001b[0;34m(FH, executor, merge_fcn, pool)\u001b[0m\n\u001b[1;32m    395\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    396\u001b[0m                 p_idm,\n\u001b[1;32m    397\u001b[0m                 total\u001b[38;5;241m=\u001b[39mprogress\u001b[38;5;241m.\u001b[39m_tasks[p_idm]\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    398\u001b[0m                 refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    399\u001b[0m             )\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Merge within process\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[43mFH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompleted\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m         merged \u001b[38;5;241m=\u001b[39m _compress(\n\u001b[1;32m    403\u001b[0m             accumulate(\n\u001b[1;32m    404\u001b[0m                 progress\u001b[38;5;241m.\u001b[39mtrack(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m             executor\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[1;32m    412\u001b[0m         )\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# Add checkpointing\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/anal/lib/python3.9/site-packages/coffea/processor/executor.py:285\u001b[0m, in \u001b[0;36m_FuturesHolder.fetch\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    283\u001b[0m bad_futures \u001b[38;5;241m=\u001b[39m [future \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m _completed \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _good_future(future)]\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompleted\u001b[38;5;241m.\u001b[39mupdate(good_futures)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m bad_futures[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mexception()\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "# prefix = 'rootfiles/'\n",
    "# fileset = {\n",
    "#             'PhiToPi0Pi0_mPhi1p0_ctau1000':\n",
    "#                 [prefix + 'BToKPhi_MuonGenFilter_mPhi1p0_ctau1000_1pb_weighted.root'],\n",
    "    \n",
    "#             'PhiToPi0Pi0_mPhi0p3_ctau1000':\n",
    "#                 [prefix + 'BToKPhi_MuonGenFilter_PhiToPi0Pi0_mPhi0p3_ctau1000_1pb_weighted.root'],\n",
    "\n",
    "#             'PhiToPi0Pi0_mPhi0p3_ctau300':\n",
    "#                 [prefix + 'BToKPhi_MuonGenFilter_PhiToPi0Pi0_mPhi0p3_ctau300_1pb_weighted.root'],\n",
    "\n",
    "#             'PhiToPiPlusPiMinus_mPhi0p3_ctau300':\n",
    "#                 [prefix + 'BToKPhi_MuonGenFilter_PhiToPiPlusPiMinus_mPhi0p3_ctau300_1pb_weighted.root'],\n",
    "\n",
    "#             'PhiToPiPlusPiMinus_mPhi0p3_ctau1000':\n",
    "#                 [prefix + 'BToKPhi_MuonGenFilter_PhiToPiPlusPiMinus_mPhi0p3_ctau1000_1pb_weighted.root'],\n",
    "#             }\n",
    "# #fileset['backgroundNew'] = [prefix + 'ParkingBPH4_2018A_goodLumi.root']\n",
    "\n",
    "prefix = 'root://cmsxrootd.fnal.gov//store/user/christiw/displacedJetMuonAnalyzer/bparking/V1p19/MC_Fall18/v1/v5/normalized/'\n",
    "fileset = {\n",
    "#             'PhiToPi0Pi0_mPhi0p3_ctau1000':\n",
    "#                 [prefix + 'BToKPhi_MuonGenFilter_PhiToPi0Pi0_mPhi0p3_ctau1000_1pb_weighted.root'],\n",
    "\n",
    "#              'PhiToPi0Pi0_mPhi0p3_ctau300':\n",
    "#                  [prefix + '/BToKPhi_MuonGenFilter_PhiToPi0Pi0_mPhi0p3_ctau300_1pb_weighted.root'],\n",
    "\n",
    "#             'PhiToPiPlusPiMinus_mPhi0p3_ctau300':\n",
    "#                 [prefix + 'BToKPhi_MuonGenFilter_PhiToPiPlusPiMinus_mPhi0p3_ctau300_1pb_weighted.root'],\n",
    "\n",
    "#             'PhiToPiPlusPiMinus_mPhi0p3_ctau1000':\n",
    "#                 [prefix + 'BToKPhi_MuonGenFilter_PhiToPiPlusPiMinus_mPhi0p3_ctau1000_1pb_weighted.root'],\n",
    "            }\n",
    "#fileset['PhiToPi0Pi0_mPhi1p0_ctau1000'] = ['root://cmsxrootd.fnal.gov//store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/MC_Fall18/v2/v3/normalized/BToKPhi_MuonGenFilter_mPhi1p0_ctau1000_1pb_weighted.root',]\n",
    "fileset['backgroundNew'] = ['root://cmsxrootd.fnal.gov//store/user/christiw/displacedJetMuonAnalyzer/bparking/V1p19/Data2018_UL/v6/normalized/ParkingBPH4_2018A_goodLumi.root']\n",
    "\n",
    "\n",
    "out = processor.run_uproot_job(\n",
    "    fileset,\n",
    "    treename=\"MuonSystem\",\n",
    "    processor_instance=CSCprocessor(),\n",
    "    executor=processor.futures_executor,\n",
    "    executor_args={\"schema\": BaseSchema, \"workers\": 3},\n",
    "    # executor_args={\"schema\": BaseSchema, \"workers\": 1},\n",
    "    #maxchunks = 1,\n",
    "    #chunksize=100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a362a-39f9-4629-8c28-e8f7e30b618a",
   "metadata": {},
   "source": [
    "# Saver\n",
    "A dictionary of histogram objects as well as some other useful info is saved into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15cdad8-70be-4e22-a05e-3980e41046c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bkg_outfile.pickle'\n",
    "outfile = open(filename, 'wb')\n",
    "pickle.dump(out, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676da80c-4269-4d80-9a2d-acfd131ec9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
